{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b64ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Engineering features\n",
    "train['feature_1'] = np.where(train['loading'] < 150, 0, 1)\n",
    "test['feature_1'] = np.where(test['loading'] < 150, 0, 1)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train[['loading', 'measurement_2', 'measurement_4', 'measurement_5',\n",
    "           'measurement_6', 'measurement_7', 'measurement_8', 'measurement_15',\n",
    "           'measurement_17', 'feature_1']]\n",
    "# X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0caf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building Random Forest model\n",
    "RF_md = RandomForestClassifier(n_estimators = 300, max_depth = 3, criterion = 'gini').fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'feature': X.columns, 'Imp': RF_md.feature_importances_})\n",
    "importance = importance.sort_values(by = 'Imp', ascending = False)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "## Running RFE with Random forest\n",
    "RF_auto_feature = RFECV(estimator = RandomForestClassifier(n_estimators = 300, max_depth = 3), step = 1, scoring = 'roc_auc', min_features_to_select = 10, cv = 3, n_jobs = -1).fit(X, Y)\n",
    "\n",
    "## Appending results \n",
    "X.columns[RF_auto_feature.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[RF_auto_feature.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5320c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the decision tree on the train data-frame\n",
    "tree_md = DecisionTreeClassifier(max_depth = 3).fit(X, Y)\n",
    "\n",
    "## Visualizing the decision-tree model \n",
    "fig = plt.figure(figsize = (25, 15))\n",
    "plot_tree(tree_md, feature_names = X.columns, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (18, 12))\n",
    "\n",
    "sns.boxplot(ax = axes[0], x = 'failure', y = 'loading', hue = 'failure', data = train)\n",
    "sns.boxplot(ax = axes[1], x = 'failure', y = 'measurement_3', hue = 'failure', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29802bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cca03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca92617",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63eb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76298d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the model \n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'uniform')\n",
    "X_new = knn_imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f18690",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e27037",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80665bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd594086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46300733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3feb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893db98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aae475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ccbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4edb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[['product_code', 'attribute_0', 'attribute_1']])\n",
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c22dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[['product_code', 'attribute_0', 'attribute_1']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['failure'].value_counts() / train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e806b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = pd.get_dummies(test[['product_code', 'attribute_0', 'attribute_1']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2480d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974ec8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "120 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.49144444 0.58792262 0.58791902\n",
      "        nan        nan        nan 0.5               nan 0.58762996\n",
      " 0.56935907 0.5874381  0.58743768        nan        nan        nan\n",
      " 0.5898217         nan 0.58967075 0.58672108 0.58788423 0.58788452\n",
      "        nan        nan        nan 0.58823161        nan 0.58822264\n",
      " 0.58778637 0.58779505 0.58779611        nan        nan        nan\n",
      " 0.58781017        nan 0.58779358 0.58777806 0.58774624 0.5877465\n",
      "        nan        nan        nan 0.58777439        nan 0.58774184\n",
      " 0.58775635 0.58773698 0.58773613        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 1000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa36d128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a97d542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5898217001986322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecafcba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, max_iter=1000, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c42d127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.467620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.491704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_4</td>\n",
       "      <td>0.196130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.077022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_11</td>\n",
       "      <td>0.057501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>measurement_9</td>\n",
       "      <td>0.050645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>measurement_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>measurement_8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>measurement_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>measurement_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>measurement_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>measurement_13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>measurement_14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>measurement_15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>measurement_16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>measurement_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>measurement_5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  2.467620\n",
       "1           measurement_17  0.491704\n",
       "2            measurement_4  0.196130\n",
       "3   attribute_0_material_5  0.077022\n",
       "4           measurement_11  0.057501\n",
       "5            measurement_9  0.050645\n",
       "6            measurement_7  0.000000\n",
       "7            measurement_8  0.000000\n",
       "8           measurement_10  0.000000\n",
       "9            measurement_3  0.000000\n",
       "10          measurement_12  0.000000\n",
       "11          measurement_13  0.000000\n",
       "12          measurement_14  0.000000\n",
       "13          measurement_15  0.000000\n",
       "14          measurement_16  0.000000\n",
       "15           measurement_6  0.000000\n",
       "16           measurement_5  0.000000\n",
       "17  attribute_0_material_7  0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e295fd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5917109597291497\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:5].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:5].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:5].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b089758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5917147420076923\n"
     ]
    }
   ],
   "source": [
    "logit_2 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:6].values], Y)\n",
    "logit_2_pred = logit_2.predict_proba(X[coefs['feature'].loc[0:6].values])[:, 1]\n",
    "logit_2_score = roc_auc_score(Y, logit_2_pred)\n",
    "print('The area under the ROC curve is:', logit_2_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_2_test_pred = logit_2.predict_proba(test[coefs['feature'].loc[0:6].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_2_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30801afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5920820884073509\n"
     ]
    }
   ],
   "source": [
    "logit_3 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:7].values], Y)\n",
    "logit_3_pred = logit_3.predict_proba(X[coefs['feature'].loc[0:7].values])[:, 1]\n",
    "logit_3_score = roc_auc_score(Y, logit_3_pred)\n",
    "print('The area under the ROC curve is:', logit_3_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_3_test_pred = logit_3.predict_proba(test[coefs['feature'].loc[0:7].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_3_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c99a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5921029205544915\n"
     ]
    }
   ],
   "source": [
    "logit_4 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:8].values], Y)\n",
    "logit_4_pred = logit_4.predict_proba(X[coefs['feature'].loc[0:8].values])[:, 1]\n",
    "logit_4_score = roc_auc_score(Y, logit_4_pred)\n",
    "print('The area under the ROC curve is:', logit_4_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_4_test_pred = logit_4.predict_proba(test[coefs['feature'].loc[0:8].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_4_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50ce756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.592213952006473\n"
     ]
    }
   ],
   "source": [
    "logit_5 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:9].values], Y)\n",
    "logit_5_pred = logit_5.predict_proba(X[coefs['feature'].loc[0:9].values])[:, 1]\n",
    "logit_5_score = roc_auc_score(Y, logit_5_pred)\n",
    "print('The area under the ROC curve is:', logit_5_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_5_test_pred = logit_5.predict_proba(test[coefs['feature'].loc[0:9].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_5_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "216abafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932685054175725\n"
     ]
    }
   ],
   "source": [
    "logit_6 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:10].values], Y)\n",
    "logit_6_pred = logit_6.predict_proba(X[coefs['feature'].loc[0:10].values])[:, 1]\n",
    "logit_6_score = roc_auc_score(Y, logit_6_pred)\n",
    "print('The area under the ROC curve is:', logit_6_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_6_test_pred = logit_6.predict_proba(test[coefs['feature'].loc[0:10].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_6_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fae5ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932727446156705\n"
     ]
    }
   ],
   "source": [
    "logit_7 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:11].values], Y)\n",
    "logit_7_pred = logit_7.predict_proba(X[coefs['feature'].loc[0:11].values])[:, 1]\n",
    "logit_7_score = roc_auc_score(Y, logit_7_pred)\n",
    "print('The area under the ROC curve is:', logit_7_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_7_test_pred = logit_7.predict_proba(test[coefs['feature'].loc[0:11].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_7_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346abf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932892106426143\n"
     ]
    }
   ],
   "source": [
    "logit_8 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:12].values], Y)\n",
    "logit_8_pred = logit_8.predict_proba(X[coefs['feature'].loc[0:12].values])[:, 1]\n",
    "logit_8_score = roc_auc_score(Y, logit_8_pred)\n",
    "print('The area under the ROC curve is:', logit_8_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_8_test_pred = logit_8.predict_proba(test[coefs['feature'].loc[0:12].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_8_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce5cda8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5935365141212808\n"
     ]
    }
   ],
   "source": [
    "logit_9 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:13].values], Y)\n",
    "logit_9_pred = logit_9.predict_proba(X[coefs['feature'].loc[0:13].values])[:, 1]\n",
    "logit_9_score = roc_auc_score(Y, logit_9_pred)\n",
    "print('The area under the ROC curve is:', logit_9_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_9_test_pred = logit_9.predict_proba(test[coefs['feature'].loc[0:13].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_9_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_9.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf05b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5936143258292842\n"
     ]
    }
   ],
   "source": [
    "logit_10 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:14].values], Y)\n",
    "logit_10_pred = logit_10.predict_proba(X[coefs['feature'].loc[0:14].values])[:, 1]\n",
    "logit_10_score = roc_auc_score(Y, logit_10_pred)\n",
    "print('The area under the ROC curve is:', logit_10_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_10_test_pred = logit_10.predict_proba(test[coefs['feature'].loc[0:14].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_10_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_10.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "936b8647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.593843741753501\n"
     ]
    }
   ],
   "source": [
    "logit_11 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:15].values], Y)\n",
    "logit_11_pred = logit_11.predict_proba(X[coefs['feature'].loc[0:15].values])[:, 1]\n",
    "logit_11_score = roc_auc_score(Y, logit_11_pred)\n",
    "print('The area under the ROC curve is:', logit_11_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_11_test_pred = logit_11.predict_proba(test[coefs['feature'].loc[0:15].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_11_test_pred})\n",
    "data_out.to_csv('Logistic_submission_11.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c9eaf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5938162335039666\n"
     ]
    }
   ],
   "source": [
    "logit_12 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:16].values], Y)\n",
    "logit_12_pred = logit_12.predict_proba(X[coefs['feature'].loc[0:16].values])[:, 1]\n",
    "logit_12_score = roc_auc_score(Y, logit_12_pred)\n",
    "print('The area under the ROC curve is:', logit_12_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_12_test_pred = logit_12.predict_proba(test[coefs['feature'].loc[0:16].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_12_test_pred})\n",
    "data_out.to_csv('Logistic_submission_12.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed6cff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937585262564042\n"
     ]
    }
   ],
   "source": [
    "logit_13 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:17].values], Y)\n",
    "logit_13_pred = logit_13.predict_proba(X[coefs['feature'].loc[0:17].values])[:, 1]\n",
    "logit_13_score = roc_auc_score(Y, logit_13_pred)\n",
    "print('The area under the ROC curve is:', logit_13_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_13_test_pred = logit_13.predict_proba(test[coefs['feature'].loc[0:17].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_13_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_13.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a26876f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937601339363217\n"
     ]
    }
   ],
   "source": [
    "logit_14 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:18].values], Y)\n",
    "logit_14_pred = logit_14.predict_proba(X[coefs['feature'].loc[0:18].values])[:, 1]\n",
    "logit_14_score = roc_auc_score(Y, logit_14_pred)\n",
    "print('The area under the ROC curve is:', logit_14_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_14_test_pred = logit_14.predict_proba(test[coefs['feature'].loc[0:18].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_14_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_14.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7072dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937781145669769\n"
     ]
    }
   ],
   "source": [
    "logit_15 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:19].values], Y)\n",
    "logit_15_pred = logit_15.predict_proba(X[coefs['feature'].loc[0:19].values])[:, 1]\n",
    "logit_15_score = roc_auc_score(Y, logit_15_pred)\n",
    "print('The area under the ROC curve is:', logit_15_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_15_test_pred = logit_15.predict_proba(test[coefs['feature'].loc[0:19].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_15_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_15.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0c2cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937811522358737\n"
     ]
    }
   ],
   "source": [
    "logit_16 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:20].values], Y)\n",
    "logit_16_pred = logit_16.predict_proba(X[coefs['feature'].loc[0:20].values])[:, 1]\n",
    "logit_16_score = roc_auc_score(Y, logit_16_pred)\n",
    "print('The area under the ROC curve is:', logit_16_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_16_test_pred = logit_16.predict_proba(test[coefs['feature'].loc[0:20].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_16_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_16.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f8e12cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937849768217824\n"
     ]
    }
   ],
   "source": [
    "logit_17 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:21].values], Y)\n",
    "logit_17_pred = logit_17.predict_proba(X[coefs['feature'].loc[0:21].values])[:, 1]\n",
    "logit_17_score = roc_auc_score(Y, logit_17_pred)\n",
    "print('The area under the ROC curve is:', logit_17_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_17_test_pred = logit_17.predict_proba(test[coefs['feature'].loc[0:21].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_17_test_pred})\n",
    "data_out.to_csv('Logistic_submission_17.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "372197d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937820745364579\n"
     ]
    }
   ],
   "source": [
    "logit_18 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:22].values], Y)\n",
    "logit_18_pred = logit_18.predict_proba(X[coefs['feature'].loc[0:22].values])[:, 1]\n",
    "logit_18_score = roc_auc_score(Y, logit_18_pred)\n",
    "print('The area under the ROC curve is:', logit_18_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_18_test_pred = logit_18.predict_proba(test[coefs['feature'].loc[0:22].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_18_test_pred})\n",
    "data_out.to_csv('Logistic_submission_18.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1fceef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937853406651322\n"
     ]
    }
   ],
   "source": [
    "logit_19 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:23].values], Y)\n",
    "logit_19_pred = logit_19.predict_proba(X[coefs['feature'].loc[0:23].values])[:, 1]\n",
    "logit_19_score = roc_auc_score(Y, logit_19_pred)\n",
    "print('The area under the ROC curve is:', logit_19_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_19_test_pred = logit_19.predict_proba(test[coefs['feature'].loc[0:23].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_19_test_pred})\n",
    "data_out.to_csv('Logistic_submission_19.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d6716",
   "metadata": {},
   "source": [
    "# Ensemble Logistic Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a9c690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure_11</th>\n",
       "      <th>failure_12</th>\n",
       "      <th>failure_17</th>\n",
       "      <th>failure_18</th>\n",
       "      <th>failure_19</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.182794</td>\n",
       "      <td>0.183966</td>\n",
       "      <td>0.194206</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.189829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.143223</td>\n",
       "      <td>0.142212</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.151433</td>\n",
       "      <td>0.147782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.163431</td>\n",
       "      <td>0.163523</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>0.173041</td>\n",
       "      <td>0.173654</td>\n",
       "      <td>0.169425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.167601</td>\n",
       "      <td>0.167822</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.175854</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.172829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0.301532</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.318281</td>\n",
       "      <td>0.317976</td>\n",
       "      <td>0.318431</td>\n",
       "      <td>0.311812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26575</td>\n",
       "      <td>0.142280</td>\n",
       "      <td>0.142407</td>\n",
       "      <td>0.150982</td>\n",
       "      <td>0.150678</td>\n",
       "      <td>0.151078</td>\n",
       "      <td>0.147485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26576</td>\n",
       "      <td>0.143446</td>\n",
       "      <td>0.143347</td>\n",
       "      <td>0.150532</td>\n",
       "      <td>0.150181</td>\n",
       "      <td>0.150771</td>\n",
       "      <td>0.147655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26577</td>\n",
       "      <td>0.201760</td>\n",
       "      <td>0.202467</td>\n",
       "      <td>0.214964</td>\n",
       "      <td>0.214645</td>\n",
       "      <td>0.215149</td>\n",
       "      <td>0.209797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26578</td>\n",
       "      <td>0.119192</td>\n",
       "      <td>0.119385</td>\n",
       "      <td>0.125221</td>\n",
       "      <td>0.124935</td>\n",
       "      <td>0.125428</td>\n",
       "      <td>0.122832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26579</td>\n",
       "      <td>0.153112</td>\n",
       "      <td>0.153706</td>\n",
       "      <td>0.163677</td>\n",
       "      <td>0.163363</td>\n",
       "      <td>0.163836</td>\n",
       "      <td>0.159539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  failure_11  failure_12  failure_17  failure_18  failure_19   failure\n",
       "0  26570    0.182794    0.183966    0.194206    0.193855    0.194325  0.189829\n",
       "1  26571    0.143223    0.142212    0.151202    0.150841    0.151433  0.147782\n",
       "2  26572    0.163431    0.163523    0.173477    0.173041    0.173654  0.169425\n",
       "3  26573    0.167601    0.167822    0.176308    0.175854    0.176560  0.172829\n",
       "4  26574    0.301532    0.302842    0.318281    0.317976    0.318431  0.311812\n",
       "5  26575    0.142280    0.142407    0.150982    0.150678    0.151078  0.147485\n",
       "6  26576    0.143446    0.143347    0.150532    0.150181    0.150771  0.147655\n",
       "7  26577    0.201760    0.202467    0.214964    0.214645    0.215149  0.209797\n",
       "8  26578    0.119192    0.119385    0.125221    0.124935    0.125428  0.122832\n",
       "9  26579    0.153112    0.153706    0.163677    0.163363    0.163836  0.159539"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_11 = pd.read_csv('Logistic_submission_11.csv')\n",
    "logit_11.columns = ['id', 'failure_11']\n",
    "\n",
    "logit_12 = pd.read_csv('Logistic_submission_12.csv')\n",
    "logit_12.columns = ['id', 'failure_12']\n",
    "\n",
    "logit_17 = pd.read_csv('Logistic_submission_17.csv')\n",
    "logit_17.columns = ['id', 'failure_17']\n",
    "\n",
    "logit_18 = pd.read_csv('Logistic_submission_18.csv')\n",
    "logit_18.columns = ['id', 'failure_18']\n",
    "\n",
    "logit_19 = pd.read_csv('Logistic_submission_19.csv')\n",
    "logit_19.columns = ['id', 'failure_19']\n",
    "\n",
    "logit = pd.merge(logit_11, logit_12, on = 'id')\n",
    "logit = pd.merge(logit, logit_17, on = 'id')\n",
    "logit = pd.merge(logit, logit_18, on = 'id')\n",
    "logit = pd.merge(logit, logit_19, on = 'id')\n",
    "\n",
    "w_11 = 0.593843741753501\n",
    "w_12 = 0.5938162335039666\n",
    "w_17 = 0.5937849768217824\n",
    "w_18 = 0.5937820745364579\n",
    "w_19 = 0.5937853406651322\n",
    "w_tot = w_11 + w_12 + w_17 + w_18 + w_19\n",
    "\n",
    "w_11 = w_11 / w_tot\n",
    "w_12 = w_12 / w_tot\n",
    "w_17 = w_17 / w_tot\n",
    "w_18 = w_18 / w_tot\n",
    "w_19 = w_19 / w_tot\n",
    "\n",
    "logit['failure'] = w_11*logit['failure_11'] + w_12*logit['failure_12'] + w_17*logit['failure_17'] + w_18*logit['failure_18'] + w_19*logit['failure_19']\n",
    "logit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b064b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.189829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.147782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.169425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.172829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0.311812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   failure\n",
       "0  26570  0.189829\n",
       "1  26571  0.147782\n",
       "2  26572  0.169425\n",
       "3  26573  0.172829\n",
       "4  26574  0.311812"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = logit[['id', 'failure']]\n",
    "logit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e52bd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.to_csv('Logistic_submission_ensemble.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca920d6",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f05f73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22cbf312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_measurement = train.drop(columns = ['loading', 'attribute_2', 'attribute_3', 'measurement_17', 'failure', 'attribute_0_material_5', 'attribute_0_material_7'], axis = 1)\n",
    "test_measurement = test.drop(columns = ['loading', 'attribute_2', 'attribute_3', 'measurement_17', 'attribute_0_material_5', 'attribute_0_material_7'], axis = 1)\n",
    "\n",
    "train_measurement_trans = scaler.fit_transform(train_measurement)\n",
    "test_measurement_trans = scaler.fit_transform(test_measurement)\n",
    "\n",
    "## Running PCA\n",
    "pca = PCA(n_components = 10, svd_solver = 'full').fit(train_measurement_trans)\n",
    "\n",
    "## Creating component names\n",
    "components = ['component_' + str(i) for i in range(1, 11)]\n",
    "\n",
    "prin_comp_train = pd.DataFrame(pca.transform(train_measurement_trans), columns = components)\n",
    "prin_comp_test = pd.DataFrame(pca.transform(test_measurement_trans), columns = components)\n",
    "\n",
    "train = pd.concat([train, prin_comp_train], axis = 1)\n",
    "test = pd.concat([test, prin_comp_test], axis = 1)\n",
    "\n",
    "train = train.drop(columns = ['measurement_' + str(i) for i in range(3, 17)], axis = 1)\n",
    "test = test.drop(columns = ['measurement_' + str(i) for i in range(3, 17)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1f754e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9419fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.50394386 0.59189669 0.59193825\n",
      " 0.50072797        nan 0.58747703 0.57594994 0.58914188 0.5891445\n",
      " 0.58966553        nan 0.5901794  0.58818055 0.58900808 0.58900681\n",
      " 0.58925803        nan 0.58925937 0.58894681 0.58891164 0.58891354\n",
      " 0.58893922        nan 0.58891372 0.58888397 0.58887323 0.58887323\n",
      " 0.588894          nan 0.58887297 0.58886549 0.58886836 0.58886815]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Filling missing values with kNN\n",
    "# knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "# train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "# test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e65808e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5919382524712525\n",
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "LogisticRegression(C=0.001, max_iter=10000, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "240e5047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>0.145958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.035316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>area</td>\n",
       "      <td>0.024280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.021656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.021655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_7</td>\n",
       "      <td>0.021434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>component_1</td>\n",
       "      <td>0.017620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>component_9</td>\n",
       "      <td>0.016114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>component_2</td>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>component_4</td>\n",
       "      <td>0.007206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>component_10</td>\n",
       "      <td>0.005867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>component_6</td>\n",
       "      <td>0.005075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>component_3</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>component_5</td>\n",
       "      <td>0.002725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>component_8</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  0.145958\n",
       "1           measurement_17  0.035316\n",
       "2                     area  0.024280\n",
       "3   attribute_0_material_5  0.021656\n",
       "4   attribute_0_material_7  0.021655\n",
       "5              component_7  0.021434\n",
       "6              component_1  0.017620\n",
       "7              component_9  0.016114\n",
       "8              component_2  0.007632\n",
       "9              component_4  0.007206\n",
       "10            component_10  0.005867\n",
       "11             component_6  0.005075\n",
       "12             component_3  0.003631\n",
       "13             component_5  0.002725\n",
       "14             component_8  0.000803"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.001, penalty = 'l2', solver = 'saga', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be233bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5680349198908752\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.001, penalty = 'l2', solver = 'saga', max_iter = 10000).fit(X[coefs['feature'].loc[0:10].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:10].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:10].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_top_6_area.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f92abd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute_0_material_5</th>\n",
       "      <th>attribute_0_material_7</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.10</td>\n",
       "      <td>18.040</td>\n",
       "      <td>12.518</td>\n",
       "      <td>15.748</td>\n",
       "      <td>19.292</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.89</td>\n",
       "      <td>18.213</td>\n",
       "      <td>11.540</td>\n",
       "      <td>17.717</td>\n",
       "      <td>17.893</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.889</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.43</td>\n",
       "      <td>18.057</td>\n",
       "      <td>11.652</td>\n",
       "      <td>16.738</td>\n",
       "      <td>18.240</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.07</td>\n",
       "      <td>17.295</td>\n",
       "      <td>11.188</td>\n",
       "      <td>18.576</td>\n",
       "      <td>18.339</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.06</td>\n",
       "      <td>19.346</td>\n",
       "      <td>12.950</td>\n",
       "      <td>16.990</td>\n",
       "      <td>15.746</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loading  measurement_3  measurement_4  measurement_5  measurement_6  \\\n",
       "0    80.10         18.040         12.518         15.748         19.292   \n",
       "1    84.89         18.213         11.540         17.717         17.893   \n",
       "2    82.43         18.057         11.652         16.738         18.240   \n",
       "3   101.07         17.295         11.188         18.576         18.339   \n",
       "4   188.06         19.346         12.950         16.990         15.746   \n",
       "\n",
       "   measurement_7  measurement_8  measurement_9  measurement_10  \\\n",
       "0         11.739         20.155         10.672          15.859   \n",
       "1         12.748         17.889         12.448          17.947   \n",
       "2         12.718         18.288         12.715          15.607   \n",
       "3         12.583         19.060         12.471          16.346   \n",
       "4         11.306         18.093         10.337          17.082   \n",
       "\n",
       "   measurement_11  measurement_12  measurement_13  measurement_14  \\\n",
       "0          17.594          15.193          15.029             NaN   \n",
       "1          17.915          11.755          14.732          15.425   \n",
       "2             NaN          13.798          16.711          18.631   \n",
       "3          18.377          10.020          15.250          15.562   \n",
       "4          19.932          12.428          16.182          12.760   \n",
       "\n",
       "   measurement_15  measurement_16  measurement_17  failure  \\\n",
       "0          13.034          14.684         764.100        0   \n",
       "1          14.395          15.631         682.057        0   \n",
       "2          14.094          17.946         663.376        0   \n",
       "3          16.154          17.172         826.282        0   \n",
       "4          13.153          16.412         579.885        0   \n",
       "\n",
       "   attribute_0_material_5  attribute_0_material_7  area  \n",
       "0                       0                       1    45  \n",
       "1                       0                       1    45  \n",
       "2                       0                       1    45  \n",
       "3                       0                       1    45  \n",
       "4                       0                       1    45  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06041a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='failure', ylabel='area'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(data = train, y = 'area', x = 'failure', hue = 'failure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0de3cc",
   "metadata": {},
   "source": [
    "# Imputing by Product Category (best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e911cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "# knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "# train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "# test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd03ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute_by_product(data):\n",
    "    \n",
    "    ## Extracting product codes\n",
    "    prod_code = data['product_code'].unique()\n",
    "    \n",
    "    ## Defining the k-NN model\n",
    "    knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "    \n",
    "    ## Defining list to store data \n",
    "    data_out = list()\n",
    "    \n",
    "    for i in range(0, len(prod_code)):\n",
    "        \n",
    "        ## Subsetting the data \n",
    "        data_temp = data[data['product_code'] == prod_code[i]].reset_index(drop = True)\n",
    "        data_temp = data_temp.drop(columns = 'product_code', axis = 1)\n",
    "        \n",
    "        ## k-NN imputation\n",
    "        data_temp = pd.DataFrame(knn_imputer.fit_transform(data_temp), columns = data.columns[1:])\n",
    "        \n",
    "        ## Storing imputed data\n",
    "        data_out.append(data_temp)\n",
    "        \n",
    "    return pd.concat(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2732293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-NN imputation\n",
    "train = knn_impute_by_product(train)\n",
    "test = knn_impute_by_product(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "048980cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "group_1 = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "train['group_1_avg'] = np.mean(train[group_1], axis = 1)\n",
    "train['group_1_std'] = np.std(train[group_1], axis = 1)\n",
    "train['group_1_IQR'] = np.percentile(train[group_1], 75) - np.percentile(train[group_1], 25)\n",
    "train['group_1_min'] = train[group_1].min(axis = 1)\n",
    "train['group_1_max'] = train[group_1].max(axis = 1)\n",
    "\n",
    "test['group_1_avg'] = np.mean(test[group_1], axis = 1)\n",
    "test['group_1_std'] = np.std(test[group_1], axis = 1) \n",
    "test['group_1_IQR'] = np.percentile(test[group_1], 75) - np.percentile(test[group_1], 25)\n",
    "test['group_1_min'] = test[group_1].min(axis = 1)\n",
    "test['group_1_max'] = test[group_1].max(axis = 1)\n",
    "\n",
    "\n",
    "group_2 = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['group_2_avg'] = np.mean(train[group_2], axis = 1)\n",
    "train['group_2_std'] = np.std(train[group_2], axis = 1)\n",
    "train['group_2_IQR'] = np.percentile(train[group_2], 75) - np.percentile(train[group_2], 25)\n",
    "train['group_2_min'] = train[group_2].min(axis = 1)\n",
    "train['group_2_max'] = train[group_2].max(axis = 1)\n",
    "\n",
    "test['group_2_avg'] = np.mean(test[group_2], axis = 1)\n",
    "test['group_2_std'] = np.std(test[group_2], axis = 1)\n",
    "test['group_2_IQR'] = np.percentile(test[group_2], 75) - np.percentile(test[group_2], 25)\n",
    "test['group_2_min'] = test[group_2].min(axis = 1)\n",
    "test['group_2_max'] = test[group_2].max(axis = 1)\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "\n",
    "train = train.drop(columns = group_1, axis = 1)\n",
    "train = train.drop(columns = group_2, axis = 1)\n",
    "\n",
    "test = test.drop(columns = group_1, axis = 1)\n",
    "test = test.drop(columns = group_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea109cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute_0_material_5</th>\n",
       "      <th>attribute_0_material_7</th>\n",
       "      <th>area</th>\n",
       "      <th>group_1_avg</th>\n",
       "      <th>group_1_std</th>\n",
       "      <th>group_1_IQR</th>\n",
       "      <th>group_1_min</th>\n",
       "      <th>group_1_max</th>\n",
       "      <th>group_2_avg</th>\n",
       "      <th>group_2_std</th>\n",
       "      <th>group_2_IQR</th>\n",
       "      <th>group_2_min</th>\n",
       "      <th>group_2_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.10</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.698816</td>\n",
       "      <td>2.123658</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>10.672</td>\n",
       "      <td>18.04000</td>\n",
       "      <td>16.73350</td>\n",
       "      <td>3.322982</td>\n",
       "      <td>3.997</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.89</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>2.398674</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>11.540</td>\n",
       "      <td>18.21300</td>\n",
       "      <td>16.56175</td>\n",
       "      <td>2.203016</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.43</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.784577</td>\n",
       "      <td>2.454714</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>11.652</td>\n",
       "      <td>18.63477</td>\n",
       "      <td>16.49600</td>\n",
       "      <td>2.268515</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.07</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.983500</td>\n",
       "      <td>2.657732</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>10.020</td>\n",
       "      <td>18.37700</td>\n",
       "      <td>17.13950</td>\n",
       "      <td>2.643499</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.06</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.058200</td>\n",
       "      <td>3.031408</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>10.337</td>\n",
       "      <td>19.93200</td>\n",
       "      <td>15.53375</td>\n",
       "      <td>2.578243</td>\n",
       "      <td>3.997</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loading  measurement_17  failure  attribute_0_material_5  \\\n",
       "0    80.10         764.100      0.0                     0.0   \n",
       "1    84.89         682.057      0.0                     0.0   \n",
       "2    82.43         663.376      0.0                     0.0   \n",
       "3   101.07         826.282      0.0                     0.0   \n",
       "4   188.06         579.885      0.0                     0.0   \n",
       "\n",
       "   attribute_0_material_7  area  group_1_avg  group_1_std  group_1_IQR  \\\n",
       "0                     1.0  45.0    14.698816     2.123658      4.64352   \n",
       "1                     1.0  45.0    15.000100     2.398674      4.64352   \n",
       "2                     1.0  45.0    15.784577     2.454714      4.64352   \n",
       "3                     1.0  45.0    14.983500     2.657732      4.64352   \n",
       "4                     1.0  45.0    15.058200     3.031408      4.64352   \n",
       "\n",
       "   group_1_min  group_1_max  group_2_avg  group_2_std  group_2_IQR  \\\n",
       "0       10.672     18.04000     16.73350     3.322982        3.997   \n",
       "1       11.540     18.21300     16.56175     2.203016        3.997   \n",
       "2       11.652     18.63477     16.49600     2.268515        3.997   \n",
       "3       10.020     18.37700     17.13950     2.643499        3.997   \n",
       "4       10.337     19.93200     15.53375     2.578243        3.997   \n",
       "\n",
       "   group_2_min  group_2_max  \n",
       "0       11.739       20.155  \n",
       "1       12.748       17.893  \n",
       "2       12.718       18.288  \n",
       "3       12.583       19.060  \n",
       "4       11.306       18.093  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354865e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.4913598  0.58750938 0.58750904\n",
      " 0.50072797        nan 0.58750034 0.57663227 0.58827259 0.588275\n",
      " 0.5900976         nan 0.59018491 0.58988232 0.58948926 0.58948719\n",
      " 0.58951128        nan 0.58960177 0.58938549 0.58917278 0.58917304\n",
      " 0.58913425        nan 0.58894913 0.58904516 0.58896893 0.5889694\n",
      " 0.58913877        nan 0.58887393 0.5888829  0.58887795 0.58887719]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f67097d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5901849079405923\n",
      "{'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "LogisticRegression(C=0.1, max_iter=10000, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94a29926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.520016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_2_avg</td>\n",
       "      <td>0.342762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area</td>\n",
       "      <td>0.045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.022742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.016343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>group_1_max</td>\n",
       "      <td>0.008903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>group_1_avg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group_1_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>group_1_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>group_1_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>group_2_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>group_2_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>group_2_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>group_2_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  2.520016\n",
       "1              group_2_avg  0.342762\n",
       "2           measurement_17  0.249400\n",
       "3                     area  0.045618\n",
       "4   attribute_0_material_5  0.022742\n",
       "5   attribute_0_material_7  0.016343\n",
       "6              group_1_max  0.008903\n",
       "7              group_1_avg  0.000000\n",
       "8              group_1_std  0.000000\n",
       "9              group_1_IQR  0.000000\n",
       "10             group_1_min  0.000000\n",
       "11             group_2_std  0.000000\n",
       "12             group_2_IQR  0.000000\n",
       "13             group_2_min  0.000000\n",
       "14             group_2_max  0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9be176f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5910694446732568\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 10000).fit(X[coefs['feature'].loc[0:6].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:6].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:6].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6_area_knn_avg_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637a152",
   "metadata": {},
   "source": [
    "## Another Look 08/09/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06878fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "train['measurement_3_missing'] = train['measurement_3'].isna()\n",
    "train['measurement_5_missing'] = train['measurement_5'].isna()\n",
    "\n",
    "test['measurement_3_missing'] = test['measurement_3'].isna()\n",
    "test['measurement_5_missing'] = test['measurement_5'].isna()\n",
    "\n",
    "def knn_impute_by_product(data):\n",
    "    \n",
    "    ## Extracting product codes\n",
    "    prod_code = data['product_code'].unique()\n",
    "    \n",
    "    ## Defining the k-NN model\n",
    "    knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "    \n",
    "    ## Defining list to store data \n",
    "    data_out = list()\n",
    "    \n",
    "    for i in range(0, len(prod_code)):\n",
    "        \n",
    "        ## Subsetting the data \n",
    "        data_temp = data[data['product_code'] == prod_code[i]].reset_index(drop = True)\n",
    "        data_temp = data_temp.drop(columns = 'product_code', axis = 1)\n",
    "        \n",
    "        ## k-NN imputation\n",
    "        data_temp = pd.DataFrame(knn_imputer.fit_transform(data_temp), columns = data.columns[1:])\n",
    "        \n",
    "        ## Storing imputed data\n",
    "        data_out.append(data_temp)\n",
    "        \n",
    "    return pd.concat(data_out)\n",
    "\n",
    "## k-NN imputation\n",
    "train = knn_impute_by_product(train)\n",
    "test = knn_impute_by_product(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96965fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "# train['measurement_3_missing'] = train['measurement_3'].isna()\n",
    "# train['measurement_5_missing'] = train['measurement_5'].isna()\n",
    "\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "# test['measurement_3_missing'] = test['measurement_3'].isna()\n",
    "# test['measurement_5_missing'] = test['measurement_5'].isna()\n",
    "\n",
    "group_1 = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "train['group_1_avg'] = np.mean(train[group_1], axis = 1)\n",
    "train['group_1_std'] = np.std(train[group_1], axis = 1)\n",
    "train['group_1_IQR'] = np.percentile(train[group_1], 75) - np.percentile(train[group_1], 25)\n",
    "train['group_1_min'] = train[group_1].min(axis = 1)\n",
    "train['group_1_max'] = train[group_1].max(axis = 1)\n",
    "# train['group_1_pct_values_above_mean'] = np.sum((train[group_1] - np.mean(train[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "test['group_1_avg'] = np.mean(test[group_1], axis = 1)\n",
    "test['group_1_std'] = np.std(test[group_1], axis = 1) \n",
    "test['group_1_IQR'] = np.percentile(test[group_1], 75) - np.percentile(test[group_1], 25)\n",
    "test['group_1_min'] = test[group_1].min(axis = 1)\n",
    "test['group_1_max'] = test[group_1].max(axis = 1)\n",
    "# test['group_1_pct_values_above_mean'] = np.sum((test[group_1] - np.mean(test[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "\n",
    "group_2 = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['group_2_avg'] = np.mean(train[group_2], axis = 1)\n",
    "train['group_2_std'] = np.std(train[group_2], axis = 1)\n",
    "train['group_2_IQR'] = np.percentile(train[group_2], 75) - np.percentile(train[group_2], 25)\n",
    "train['group_2_min'] = train[group_2].min(axis = 1)\n",
    "train['group_2_max'] = train[group_2].max(axis = 1)\n",
    "# train['group_2_pct_values_above_mean'] = np.sum((train[group_2] - np.mean(train[group_2], axis = 0)) > 0, axis = 1)\n",
    "train['meas_17/group_2_avg'] = train['measurement_17'] / train['group_2_avg']\n",
    "\n",
    "test['group_2_avg'] = np.mean(test[group_2], axis = 1)\n",
    "test['group_2_std'] = np.std(test[group_2], axis = 1)\n",
    "test['group_2_IQR'] = np.percentile(test[group_2], 75) - np.percentile(test[group_2], 25)\n",
    "test['group_2_min'] = test[group_2].min(axis = 1)\n",
    "test['group_2_max'] = test[group_2].max(axis = 1)\n",
    "# test['group_2_pct_values_above_mean'] = np.sum((test[group_2] - np.mean(test[group_2], axis = 0)) > 0, axis = 1) \n",
    "test['meas_17/group_2_avg'] = test['measurement_17'] / test['group_2_avg']\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "\n",
    "train = train.drop(columns = group_1, axis = 1)\n",
    "train = train.drop(columns = group_2, axis = 1)\n",
    "\n",
    "test = test.drop(columns = group_1, axis = 1)\n",
    "test = test.drop(columns = group_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b426dfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='failure', ylabel='meas_17/group_2_avg'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data = train, x = 'failure', y = 'meas_17/group_2_avg', hue = 'failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1540c065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute_0_material_5</th>\n",
       "      <th>attribute_0_material_7</th>\n",
       "      <th>measurement_3_missing</th>\n",
       "      <th>measurement_5_missing</th>\n",
       "      <th>area</th>\n",
       "      <th>group_1_avg</th>\n",
       "      <th>group_1_std</th>\n",
       "      <th>group_1_IQR</th>\n",
       "      <th>group_1_min</th>\n",
       "      <th>group_1_max</th>\n",
       "      <th>group_2_avg</th>\n",
       "      <th>group_2_std</th>\n",
       "      <th>group_2_IQR</th>\n",
       "      <th>group_2_min</th>\n",
       "      <th>group_2_max</th>\n",
       "      <th>meas_17/group_2_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.10</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.698613</td>\n",
       "      <td>2.123690</td>\n",
       "      <td>4.644</td>\n",
       "      <td>10.672</td>\n",
       "      <td>18.040</td>\n",
       "      <td>16.73350</td>\n",
       "      <td>3.322982</td>\n",
       "      <td>3.997</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "      <td>45.662892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.89</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>2.398674</td>\n",
       "      <td>4.644</td>\n",
       "      <td>11.540</td>\n",
       "      <td>18.213</td>\n",
       "      <td>16.56175</td>\n",
       "      <td>2.203016</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.893</td>\n",
       "      <td>41.182665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.43</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.783969</td>\n",
       "      <td>2.454008</td>\n",
       "      <td>4.644</td>\n",
       "      <td>11.652</td>\n",
       "      <td>18.631</td>\n",
       "      <td>16.49600</td>\n",
       "      <td>2.268515</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "      <td>40.214355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.07</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.983500</td>\n",
       "      <td>2.657732</td>\n",
       "      <td>4.644</td>\n",
       "      <td>10.020</td>\n",
       "      <td>18.377</td>\n",
       "      <td>17.13950</td>\n",
       "      <td>2.643499</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "      <td>48.209224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.06</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.058200</td>\n",
       "      <td>3.031408</td>\n",
       "      <td>4.644</td>\n",
       "      <td>10.337</td>\n",
       "      <td>19.932</td>\n",
       "      <td>15.53375</td>\n",
       "      <td>2.578243</td>\n",
       "      <td>3.997</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "      <td>37.330651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loading  measurement_17  failure  attribute_0_material_5  \\\n",
       "0    80.10         764.100      0.0                     0.0   \n",
       "1    84.89         682.057      0.0                     0.0   \n",
       "2    82.43         663.376      0.0                     0.0   \n",
       "3   101.07         826.282      0.0                     0.0   \n",
       "4   188.06         579.885      0.0                     0.0   \n",
       "\n",
       "   attribute_0_material_7  measurement_3_missing  measurement_5_missing  area  \\\n",
       "0                     1.0                    0.0                    0.0  45.0   \n",
       "1                     1.0                    0.0                    0.0  45.0   \n",
       "2                     1.0                    0.0                    0.0  45.0   \n",
       "3                     1.0                    0.0                    0.0  45.0   \n",
       "4                     1.0                    0.0                    0.0  45.0   \n",
       "\n",
       "   group_1_avg  group_1_std  group_1_IQR  group_1_min  group_1_max  \\\n",
       "0    14.698613     2.123690        4.644       10.672       18.040   \n",
       "1    15.000100     2.398674        4.644       11.540       18.213   \n",
       "2    15.783969     2.454008        4.644       11.652       18.631   \n",
       "3    14.983500     2.657732        4.644       10.020       18.377   \n",
       "4    15.058200     3.031408        4.644       10.337       19.932   \n",
       "\n",
       "   group_2_avg  group_2_std  group_2_IQR  group_2_min  group_2_max  \\\n",
       "0     16.73350     3.322982        3.997       11.739       20.155   \n",
       "1     16.56175     2.203016        3.997       12.748       17.893   \n",
       "2     16.49600     2.268515        3.997       12.718       18.288   \n",
       "3     17.13950     2.643499        3.997       12.583       19.060   \n",
       "4     15.53375     2.578243        3.997       11.306       18.093   \n",
       "\n",
       "   meas_17/group_2_avg  \n",
       "0            45.662892  \n",
       "1            41.182665  \n",
       "2            40.214355  \n",
       "3            48.209224  \n",
       "4            37.330651  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ac590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.5               nan 0.5        0.58452794 0.49014112\n",
      " 0.58452566 0.58452811        nan 0.50072797        nan 0.5875108\n",
      " 0.58751043 0.5765435  0.58751106 0.5875103         nan 0.59008517\n",
      "        nan 0.59015825 0.58939665 0.58972636 0.58939614 0.58939568\n",
      "        nan 0.58946634        nan 0.58956771 0.58913068 0.58932946\n",
      " 0.58913237 0.58913021        nan 0.58908976        nan 0.58892978\n",
      " 0.5889577  0.58899231 0.58895779 0.58895817        nan 0.58906863\n",
      "        nan 0.58877523 0.588799   0.58881634 0.588799   0.58879908]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['newton-cg', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3078ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5901582549043226\n",
      "{'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "LogisticRegression(C=0.1, max_iter=10000, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d469e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.520156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_2_avg</td>\n",
       "      <td>0.353565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.237812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_3_missing</td>\n",
       "      <td>0.164277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_5_missing</td>\n",
       "      <td>0.156461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>area</td>\n",
       "      <td>0.045617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.020524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.017608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group_1_max</td>\n",
       "      <td>0.008937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meas_17/group_2_avg</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>group_1_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>group_1_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>group_1_avg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>group_2_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>group_2_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>group_2_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>group_2_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>group_1_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  2.520156\n",
       "1              group_2_avg  0.353565\n",
       "2           measurement_17  0.237812\n",
       "3    measurement_3_missing  0.164277\n",
       "4    measurement_5_missing  0.156461\n",
       "5                     area  0.045617\n",
       "6   attribute_0_material_7  0.020524\n",
       "7   attribute_0_material_5  0.017608\n",
       "8              group_1_max  0.008937\n",
       "9      meas_17/group_2_avg  0.000001\n",
       "10             group_1_min  0.000000\n",
       "11             group_1_std  0.000000\n",
       "12             group_1_avg  0.000000\n",
       "13             group_2_std  0.000000\n",
       "14             group_2_IQR  0.000000\n",
       "15             group_2_min  0.000000\n",
       "16             group_2_max  0.000000\n",
       "17             group_1_IQR  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f73124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loading', 'group_2_avg', 'measurement_17',\n",
       "       'measurement_3_missing', 'measurement_5_missing', 'area',\n",
       "       'attribute_0_material_7', 'attribute_0_material_5', 'group_1_max',\n",
       "       'meas_17/group_2_avg'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs['feature'].loc[0:9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "210c9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5918597970436104\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 10000).fit(X[coefs['feature'].loc[0:8].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:8].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:8].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6_area_knn_avg_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfbd1e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5918608293433467\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 10000).fit(X[coefs['feature'].loc[0:9].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:9].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:9].values])[:, 1] \n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6_area_knn_avg_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d91e0",
   "metadata": {},
   "source": [
    "# Another Look at Regression 08/09/2022 Second Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9caa1071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "train['measurement_3_missing'] = train['measurement_3'].isna()\n",
    "train['measurement_5_missing'] = train['measurement_5'].isna()\n",
    "\n",
    "test['measurement_3_missing'] = test['measurement_3'].isna()\n",
    "test['measurement_5_missing'] = test['measurement_5'].isna()\n",
    "\n",
    "def knn_impute_by_product(data):\n",
    "    \n",
    "    ## Extracting product codes\n",
    "    prod_code = data['product_code'].unique()\n",
    "    \n",
    "    ## Defining the k-NN model\n",
    "    knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "    \n",
    "    ## Defining list to store data \n",
    "    data_out = list()\n",
    "    \n",
    "    for i in range(0, len(prod_code)):\n",
    "        \n",
    "        ## Subsetting the data \n",
    "        data_temp = data[data['product_code'] == prod_code[i]].reset_index(drop = True)\n",
    "        data_temp = data_temp.drop(columns = 'product_code', axis = 1)\n",
    "        \n",
    "        ## k-NN imputation\n",
    "        data_temp = pd.DataFrame(knn_imputer.fit_transform(data_temp), columns = data.columns[1:])\n",
    "        \n",
    "        ## Storing imputed data\n",
    "        data_out.append(data_temp)\n",
    "        \n",
    "    return pd.concat(data_out)\n",
    "\n",
    "## k-NN imputation\n",
    "train = knn_impute_by_product(train)\n",
    "test = knn_impute_by_product(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e5b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "group_1 = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "train['group_1_avg'] = np.mean(train[group_1], axis = 1)\n",
    "train['group_1_std'] = np.std(train[group_1], axis = 1)\n",
    "train['group_1_IQR'] = np.percentile(train[group_1], 75) - np.percentile(train[group_1], 25)\n",
    "train['group_1_min'] = train[group_1].min(axis = 1)\n",
    "train['group_1_max'] = train[group_1].max(axis = 1)\n",
    "# train['group_1_pct_values_above_mean'] = np.sum((train[group_1] - np.mean(train[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "test['group_1_avg'] = np.mean(test[group_1], axis = 1)\n",
    "test['group_1_std'] = np.std(test[group_1], axis = 1) \n",
    "test['group_1_IQR'] = np.percentile(test[group_1], 75) - np.percentile(test[group_1], 25)\n",
    "test['group_1_min'] = test[group_1].min(axis = 1)\n",
    "test['group_1_max'] = test[group_1].max(axis = 1)\n",
    "# test['group_1_pct_values_above_mean'] = np.sum((test[group_1] - np.mean(test[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "\n",
    "group_2 = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['group_2_avg'] = np.mean(train[group_2], axis = 1)\n",
    "train['group_2_std'] = np.std(train[group_2], axis = 1)\n",
    "train['group_2_IQR'] = np.percentile(train[group_2], 75) - np.percentile(train[group_2], 25)\n",
    "train['group_2_min'] = train[group_2].min(axis = 1)\n",
    "train['group_2_max'] = train[group_2].max(axis = 1)\n",
    "# train['group_2_pct_values_above_mean'] = np.sum((train[group_2] - np.mean(train[group_2], axis = 0)) > 0, axis = 1)\n",
    "train['meas_17/group_2_avg'] = train['measurement_17'] / train['group_2_avg']\n",
    "\n",
    "test['group_2_avg'] = np.mean(test[group_2], axis = 1)\n",
    "test['group_2_std'] = np.std(test[group_2], axis = 1)\n",
    "test['group_2_IQR'] = np.percentile(test[group_2], 75) - np.percentile(test[group_2], 25)\n",
    "test['group_2_min'] = test[group_2].min(axis = 1)\n",
    "test['group_2_max'] = test[group_2].max(axis = 1)\n",
    "# test['group_2_pct_values_above_mean'] = np.sum((test[group_2] - np.mean(test[group_2], axis = 0)) > 0, axis = 1) \n",
    "test['meas_17/group_2_avg'] = test['measurement_17'] / test['group_2_avg']\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "\n",
    "train = train.drop(columns = group_1, axis = 1)\n",
    "train = train.drop(columns = group_2, axis = 1)\n",
    "\n",
    "test = test.drop(columns = group_1, axis = 1)\n",
    "test = test.drop(columns = group_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45f3310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.5               nan 0.5        0.58855374 0.47975185\n",
      " 0.58855475 0.58855306        nan 0.50072797        nan 0.5875108\n",
      " 0.58897301 0.57970113 0.58897347 0.58897326        nan 0.59016624\n",
      "        nan 0.59015737 0.59005416 0.59069662 0.59005552 0.59005391\n",
      "        nan 0.590101          nan 0.59009364 0.58998695 0.59007879\n",
      " 0.58998593 0.58998746        nan 0.58999517        nan 0.58997046\n",
      " 0.58996737 0.58997316 0.58996724 0.58996788        nan 0.58998158\n",
      "        nan 0.58987646 0.58989528 0.58996072 0.58989503 0.58989562]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Defining input and target variables\n",
    "X = train[['loading', 'group_2_avg', 'measurement_17', 'measurement_3_missing', \n",
    "           'measurement_5_missing', 'area', 'attribute_0_material_7', \n",
    "           'attribute_0_material_5', 'group_1_max', 'meas_17/group_2_avg']]\n",
    "\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['newton-cg', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac955163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5906966175398594\n",
      "{'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression(C=0.1, max_iter=10000, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5362e6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.241465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.712481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.696965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>group_2_avg</td>\n",
       "      <td>0.300285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_3_missing</td>\n",
       "      <td>0.297727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>group_1_max</td>\n",
       "      <td>0.221456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>measurement_5_missing</td>\n",
       "      <td>0.216085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.210518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meas_17/group_2_avg</td>\n",
       "      <td>0.102512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>area</td>\n",
       "      <td>0.086294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  est_coef\n",
       "0                 loading  2.241465\n",
       "1  attribute_0_material_5  0.712481\n",
       "2  attribute_0_material_7  0.696965\n",
       "3             group_2_avg  0.300285\n",
       "4   measurement_3_missing  0.297727\n",
       "5             group_1_max  0.221456\n",
       "6   measurement_5_missing  0.216085\n",
       "7          measurement_17  0.210518\n",
       "8     meas_17/group_2_avg  0.102512\n",
       "9                    area  0.086294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logistic_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326d6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5917453386949627\n"
     ]
    }
   ],
   "source": [
    "logit_1_pred = logistic_md.predict_proba(X)[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "test = test[['loading', 'group_2_avg', 'measurement_17', 'measurement_3_missing', \n",
    "           'measurement_5_missing', 'area', 'attribute_0_material_7', \n",
    "           'attribute_0_material_5', 'group_1_max', 'meas_17/group_2_avg']]\n",
    "logit_1_test_pred = logistic_md.predict_proba(test)[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6_area_knn_avg_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a511f3",
   "metadata": {},
   "source": [
    "# Another Look (08/11/2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00791a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "train['measurement_3_missing'] = train['measurement_3'].isna()\n",
    "train['measurement_5_missing'] = train['measurement_5'].isna()\n",
    "train['measurement_3_5_missing'] = train['measurement_3_missing'] * train['measurement_5_missing']\n",
    "\n",
    "test['measurement_3_missing'] = test['measurement_3'].isna()\n",
    "test['measurement_5_missing'] = test['measurement_5'].isna()\n",
    "test['measurement_3_5_missing'] = test['measurement_3_missing'] * test['measurement_5_missing']\n",
    "\n",
    "def knn_impute_by_product(data):\n",
    "    \n",
    "    ## Extracting product codes\n",
    "    prod_code = data['product_code'].unique()\n",
    "    \n",
    "    ## Defining the k-NN model\n",
    "    knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "    \n",
    "    ## Defining list to store data \n",
    "    data_out = list()\n",
    "    \n",
    "    for i in range(0, len(prod_code)):\n",
    "        \n",
    "        ## Subsetting the data \n",
    "        data_temp = data[data['product_code'] == prod_code[i]].reset_index(drop = True)\n",
    "        data_temp = data_temp.drop(columns = 'product_code', axis = 1)\n",
    "        \n",
    "        ## k-NN imputation\n",
    "        data_temp = pd.DataFrame(knn_imputer.fit_transform(data_temp), columns = data.columns[1:])\n",
    "        \n",
    "        ## Storing imputed data\n",
    "        data_out.append(data_temp)\n",
    "        \n",
    "    return pd.concat(data_out)\n",
    "\n",
    "## k-NN imputation\n",
    "train = knn_impute_by_product(train)\n",
    "test = knn_impute_by_product(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b6ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "group_1 = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "train['group_1_avg'] = np.mean(train[group_1], axis = 1)\n",
    "train['group_1_std'] = np.std(train[group_1], axis = 1)\n",
    "train['group_1_IQR'] = np.percentile(train[group_1], 75) - np.percentile(train[group_1], 25)\n",
    "train['group_1_min'] = train[group_1].min(axis = 1)\n",
    "train['group_1_max'] = train[group_1].max(axis = 1)\n",
    "# train['group_1_pct_values_above_mean'] = np.sum((train[group_1] - np.mean(train[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "test['group_1_avg'] = np.mean(test[group_1], axis = 1)\n",
    "test['group_1_std'] = np.std(test[group_1], axis = 1) \n",
    "test['group_1_IQR'] = np.percentile(test[group_1], 75) - np.percentile(test[group_1], 25)\n",
    "test['group_1_min'] = test[group_1].min(axis = 1)\n",
    "test['group_1_max'] = test[group_1].max(axis = 1)\n",
    "# test['group_1_pct_values_above_mean'] = np.sum((test[group_1] - np.mean(test[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "\n",
    "group_2 = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['group_2_avg'] = np.mean(train[group_2], axis = 1)\n",
    "train['group_2_std'] = np.std(train[group_2], axis = 1)\n",
    "train['group_2_IQR'] = np.percentile(train[group_2], 75) - np.percentile(train[group_2], 25)\n",
    "train['group_2_min'] = train[group_2].min(axis = 1)\n",
    "train['group_2_max'] = train[group_2].max(axis = 1)\n",
    "# train['group_2_pct_values_above_mean'] = np.sum((train[group_2] - np.mean(train[group_2], axis = 0)) > 0, axis = 1)\n",
    "train['meas_17/group_2_avg'] = train['measurement_17'] / train['group_2_avg']\n",
    "\n",
    "test['group_2_avg'] = np.mean(test[group_2], axis = 1)\n",
    "test['group_2_std'] = np.std(test[group_2], axis = 1)\n",
    "test['group_2_IQR'] = np.percentile(test[group_2], 75) - np.percentile(test[group_2], 25)\n",
    "test['group_2_min'] = test[group_2].min(axis = 1)\n",
    "test['group_2_max'] = test[group_2].max(axis = 1)\n",
    "# test['group_2_pct_values_above_mean'] = np.sum((test[group_2] - np.mean(test[group_2], axis = 0)) > 0, axis = 1) \n",
    "test['meas_17/group_2_avg'] = test['measurement_17'] / test['group_2_avg']\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "\n",
    "train = train.drop(columns = group_1, axis = 1)\n",
    "train = train.drop(columns = group_2, axis = 1)\n",
    "\n",
    "test = test.drop(columns = group_1, axis = 1)\n",
    "test = test.drop(columns = group_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393c8052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.5               nan 0.5        0.58854066 0.47973286\n",
      " 0.58854188 0.58853934        nan 0.50072797        nan 0.58751512\n",
      " 0.58896314 0.57966369 0.58896268 0.58896412        nan 0.59014936\n",
      "        nan 0.59015843 0.5900448  0.59067829 0.59004358 0.59004366\n",
      "        nan 0.59003929        nan 0.59003879 0.58998438 0.5900387\n",
      " 0.58998324 0.58998434        nan 0.58994285        nan 0.58993028\n",
      " 0.59002681 0.58994166 0.59002681 0.59002618        nan 0.5900302\n",
      "        nan 0.58993929 0.58996788 0.58990375 0.5899678  0.58996831]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Defining input and target variables\n",
    "# X = train.drop(columns = 'failure', axis = 1)\n",
    "X = train[['loading', 'group_2_avg', 'measurement_17', 'measurement_3_missing', \n",
    "           'measurement_5_missing', 'area', 'attribute_0_material_7', \n",
    "           'attribute_0_material_5', 'group_1_max', 'meas_17/group_2_avg', 'measurement_3_5_missing']]\n",
    "\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['newton-cg', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ab37e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5906782863481108\n",
      "{'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression(C=0.1, max_iter=10000, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4d0d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.239736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.712993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.696994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_3_missing</td>\n",
       "      <td>0.305037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>group_2_avg</td>\n",
       "      <td>0.304755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>measurement_3_5_missing</td>\n",
       "      <td>0.247451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>group_1_max</td>\n",
       "      <td>0.222195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>measurement_5_missing</td>\n",
       "      <td>0.214305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.207475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meas_17/group_2_avg</td>\n",
       "      <td>0.103047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>area</td>\n",
       "      <td>0.085725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  est_coef\n",
       "0                   loading  2.239736\n",
       "1    attribute_0_material_5  0.712993\n",
       "2    attribute_0_material_7  0.696994\n",
       "3     measurement_3_missing  0.305037\n",
       "4               group_2_avg  0.304755\n",
       "5   measurement_3_5_missing  0.247451\n",
       "6               group_1_max  0.222195\n",
       "7     measurement_5_missing  0.214305\n",
       "8            measurement_17  0.207475\n",
       "9       meas_17/group_2_avg  0.103047\n",
       "10                     area  0.085725"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logistic_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f7a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5918964436842544\n"
     ]
    }
   ],
   "source": [
    "logit_1_pred = logistic_md.predict_proba(X)[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "test = test[['loading', 'group_2_avg', 'measurement_17', 'measurement_3_missing', \n",
    "           'measurement_5_missing', 'area', 'attribute_0_material_7', \n",
    "           'attribute_0_material_5', 'group_1_max', 'meas_17/group_2_avg', 'measurement_3_5_missing']]\n",
    "logit_1_test_pred = logistic_md.predict_proba(test)[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6_area_knn_avg_7.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
