{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52977bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import miceforest as mf\n",
    "\n",
    "## -------------------------------------------\n",
    "\n",
    "## Sanity check\n",
    "print('-- Process Starting --')\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'evan-callaghan-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key = 'Kaggle-American-Express-Default/amex_train_data.csv'\n",
    "file_key2 = 'Kaggle-American-Express-Default/amex_train_labels.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "bucket_object2 = bucket.Object(file_key2)\n",
    "\n",
    "file_object = bucket_object.get()\n",
    "file_object2 = bucket_object2.get()\n",
    "\n",
    "file_content_stream = file_object.get('Body')\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "\n",
    "## Creating data-type dictionary for reading the train data-frame\n",
    "dtype_dict = {'customer_ID': \"object\", 'S_2': \"object\", 'P_2': 'float16', 'D_39': 'float16', 'B_1': 'float16','B_2': 'float16', 'R_1': 'float16','S_3': 'float16','D_41': 'float16','B_3': 'float16','D_42': 'float16','D_43': 'float16','D_44': 'float16', 'B_4': 'float16','D_45': 'float16','B_5': 'float16','R_2': 'float16','D_46': 'float16','D_47': 'float16','D_48': 'float16', 'D_49': 'float16','B_6': 'float16','B_7': 'float16','B_8': 'float16','D_50': 'float16','D_51': 'float16','B_9': 'float16', 'R_3': 'float16','D_52': 'float16','P_3': 'float16','B_10': 'float16','D_53': 'float16','S_5': 'float16','B_11': 'float16', 'S_6': 'float16','D_54': 'float16','R_4': 'float16','S_7': 'float16','B_12': 'float16','S_8': 'float16','D_55': 'float16', 'D_56': 'float16','B_13': 'float16','R_5': 'float16','D_58': 'float16','S_9': 'float16','B_14': 'float16','D_59': 'float16', 'D_60': 'float16','D_61': 'float16','B_15': 'float16','S_11': 'float16','D_62': 'float16','D_63': 'object','D_64': 'object', 'D_65': 'float16','B_16': 'float16','B_17': 'float16','B_18': 'float16','B_19': 'float16','D_66': 'float16','B_20': 'float16', 'D_68': 'float16','S_12': 'float16','R_6': 'float16','S_13': 'float16','B_21': 'float16','D_69': 'float16','B_22': 'float16', 'D_70': 'float16','D_71': 'float16','D_72': 'float16','S_15': 'float16','B_23': 'float16','D_73': 'float16','P_4': 'float16', 'D_74': 'float16','D_75': 'float16','D_76': 'float16','B_24': 'float16','R_7': 'float16','D_77': 'float16','B_25': 'float16', 'B_26': 'float16','D_78': 'float16','D_79': 'float16','R_8': 'float16','R_9': 'float16','S_16': 'float16','D_80': 'float16', 'R_10': 'float16','R_11': 'float16','B_27': 'float16','D_81': 'float16','D_82': 'float16','S_17': 'float16','R_12': 'float16', 'B_28': 'float16','R_13': 'float16','D_83': 'float16','R_14': 'float16','R_15': 'float16','D_84': 'float16','R_16': 'float16', 'B_29': 'float16','B_30': 'float16','S_18': 'float16','D_86': 'float16','D_87': 'float16','R_17': 'float16','R_18': 'float16', 'D_88': 'float16','B_31': 'int64','S_19': 'float16','R_19': 'float16','B_32': 'float16','S_20': 'float16','R_20': 'float16', 'R_21': 'float16','B_33': 'float16','D_89': 'float16','R_22': 'float16','R_23': 'float16','D_91': 'float16','D_92': 'float16', 'D_93': 'float16','D_94': 'float16','R_24': 'float16','R_25': 'float16','D_96': 'float16','S_22': 'float16','S_23': 'float16', 'S_24': 'float16','S_25': 'float16','S_26': 'float16','D_102': 'float16','D_103': 'float16','D_104': 'float16','D_105': 'float16', 'D_106': 'float16','D_107': 'float16','B_36': 'float16','B_37': 'float16', 'R_26': 'float16','R_27': 'float16','B_38': 'float16', 'D_108': 'float16','D_109': 'float16','D_110': 'float16','D_111': 'float16','B_39': 'float16','D_112': 'float16','B_40': 'float16', 'S_27': 'float16','D_113': 'float16','D_114': 'float16','D_115': 'float16','D_116': 'float16','D_117': 'float16','D_118': 'float16', 'D_119': 'float16','D_120': 'float16','D_121': 'float16','D_122': 'float16','D_123': 'float16','D_124': 'float16','D_125': 'float16', 'D_126': 'float16','D_127': 'float16','D_128': 'float16','D_129': 'float16','B_41': 'float16','B_42': 'float16','D_130': 'float16', 'D_131': 'float16','D_132': 'float16','D_133': 'float16','R_28': 'float16','D_134': 'float16','D_135': 'float16','D_136': 'float16', 'D_137': 'float16','D_138': 'float16','D_139': 'float16','D_140': 'float16','D_141': 'float16','D_142': 'float16','D_143': 'float16', 'D_144': 'float16','D_145': 'float16'}\n",
    "\n",
    "## Reading the data\n",
    "train = pd.read_csv(file_content_stream, dtype = dtype_dict)\n",
    "train_labels = pd.read_csv(file_content_stream2)\n",
    "\n",
    "## Subsetting the data for Payment and Spend variables\n",
    "train = train[['customer_ID', 'P_2', 'P_3', 'P_4', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8', 'S_9', 'S_11', 'S_12', 'S_13', 'S_15', 'S_16', 'S_17', \n",
    "               'S_18', 'S_19', 'S_20', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27']]\n",
    "\n",
    "## Appending target labels with train data-frame\n",
    "train = train.merge(train_labels, on = 'customer_ID', how = 'left')\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46252663",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing new Payment and Spend count features with the train data-frame\n",
    "count_vars_train = train.groupby('customer_ID').agg({'P_3':['count'], 'S_3':['count'], 'S_7':['count'], \n",
    "                                                     'S_22': ['count'], 'S_23': ['count'], 'S_25': ['count']}).reset_index(drop = False)\n",
    "\n",
    "## Editing the variable names in the data-frame\n",
    "count_vars_train.columns = ['customer_ID', 'P_3_count', 'S_3_count', 'S_7_count', 'S_22_count', 'S_23_count', 'S_25_count']\n",
    "\n",
    "# Creating binary count variables\n",
    "count_vars_train['P_3_count_binary'] = np.where(count_vars_train[\"P_3_count\"] > 0, 1, 0)\n",
    "count_vars_train['S_3_count_binary'] = np.where(count_vars_train[\"S_3_count\"] > 0, 1, 0)\n",
    "count_vars_train['S_7_count_binary'] = np.where(count_vars_train[\"S_7_count\"] > 0, 1, 0)\n",
    "count_vars_train['S_22_count_binary'] = np.where(count_vars_train[\"S_22_count\"] > 0, 1, 0)\n",
    "count_vars_train['S_23_count_binary'] = np.where(count_vars_train[\"S_23_count\"] > 0, 1, 0)\n",
    "count_vars_train['S_25_count_binary'] = np.where(count_vars_train[\"S_25_count\"] > 0, 1, 0)\n",
    "\n",
    "## Sanity check\n",
    "print('-- Training counts data-frame complete -- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing the train data-frame using the Mice Forest library\n",
    "\n",
    "## Defining the input variables and dropping categorical variables\n",
    "mf_train = train.drop(columns = ['customer_ID', 'target'])\n",
    "\n",
    "# Building the miceforest kernel\n",
    "kernel_train = mf.ImputationKernel(mf_train, datasets = 5, save_all_iterations = True)\n",
    "\n",
    "## Assigning the final imputed data-frames\n",
    "train_impute = kernel_train.complete_data(dataset = 0, inplace = False)\n",
    "\n",
    "## Adding \"customer_ID\" back into the data-frames\n",
    "train_impute = pd.concat([train[['customer_ID', 'target']], train_impute], axis = 1)\n",
    "\n",
    "## Sanity check\n",
    "print('-- Training data-frame imputation complete -- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a series of aggregation functions\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "def iqr(x):\n",
    "    return np.percentile(x, 75) - np.percentile(x, 25)\n",
    "def correlation(x):\n",
    "    return pd.Series(x.values).corr(other = pd.Series(x.index), method = 'pearson')\n",
    "\n",
    "## Creating new Payment features with the cleaned train data-frame\n",
    "payment_vars_train = train_impute.groupby('customer_ID').agg({'P_2':['mean', 'median', 'sum', data_range, iqr, correlation], 'P_3':['mean', 'median', 'sum', data_range, iqr, correlation], 'P_4':['mean', 'median', 'sum', data_range, iqr, correlation]}).reset_index(drop = False)\n",
    "\n",
    "## Renaming variable names\n",
    "payment_vars_train.columns = ['customer_ID', 'P_2_mean', 'P_2_median', 'P_2_sum', 'P_2_data_range', 'P_2_iqr', 'P_2_correlation', 'P_3_mean', 'P_3_median', 'P_3_sum', 'P_3_data_range', 'P_3_iqr', 'P_3_correlation', 'P_4_mean', 'P_4_median', 'P_4_sum', 'P_4_data_range', 'P_4_iqr', 'P_4_correlation']\n",
    "\n",
    "## Creating new Spend features with the cleaned train data-frame\n",
    "spend_vars_train = train_impute.groupby('customer_ID').agg({'S_3':['median', 'sum', data_range, iqr, correlation], 'S_5':[data_range, iqr, correlation], 'S_6':['mean', 'median', 'sum', 'mad', data_range, iqr, correlation], 'S_8':['mean', 'median', 'sum', data_range, iqr, correlation], 'S_13':['mean', 'sum', 'std', 'mad', data_range, iqr, correlation], 'S_25':['mean', 'sum', 'std', 'mad', data_range, iqr, correlation], 'S_27':[data_range, iqr, correlation]}).reset_index(drop = False)\n",
    "\n",
    "spend_vars_train.columns = ['customer_ID', 'S_3_median', 'S_3_sum', 'S_3_data_range', 'S_3_iqr', 'S_3_correlation', 'S_5_data_range', 'S_5_iqr', 'S_5_correlation', 'S_6_mean', 'S_6_median', 'S_6_sum', 'S_6_mad', 'S_6_data_range', 'S_6_iqr', 'S_6_correlation', 'S_8_mean', 'S_8_median', 'S_8_sum', 'S_8_data_range', 'S_8_iqr', 'S_8_correlation', 'S_13_mean', 'S_13_sum', 'S_13_std', 'S_13_mad', 'S_13_data_range', 'S_13_iqr', 'S_13_correlation', 'S_25_mean', 'S_25_sum', 'S_25_std', 'S_25_mad', 'S_25_data_range', 'S_25_iqr', 'S_25_correlation', 'S_27_data_range', 'S_27_iqr', 'S_27_correlation']\n",
    "\n",
    "## Sanity check\n",
    "print('-- Training aggregations data-frame complete -- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining desired count features with other aggregated features to create final data-frame\n",
    "\n",
    "## Joining the Payment and Spend train data-frames\n",
    "training = payment_vars_train.merge(spend_vars_train, how = 'left', on = 'customer_ID')\n",
    "\n",
    "# ## Joining the Training and Count data-frames\n",
    "# training = training.merge(count_vars_train, how = 'left', on = 'customer_ID')\n",
    "\n",
    "## Appending target labels to training data-frame\n",
    "training = training.merge(train_labels, on = 'customer_ID', how = 'left')\n",
    "\n",
    "## -------------------------------------------\n",
    "\n",
    "## Exporting the resulting training data-frame to a csv file\n",
    "training.to_csv('amex_train_payment_spend.csv', index = False)\n",
    "\n",
    "## Sanity check\n",
    "print('-- Training data-frame complete -- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e158963",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import miceforest as mf\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from Amex_Metric import amex_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90c8ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_median</th>\n",
       "      <th>P_2_sum</th>\n",
       "      <th>P_2_data_range</th>\n",
       "      <th>P_2_iqr</th>\n",
       "      <th>P_2_correlation</th>\n",
       "      <th>P_3_mean</th>\n",
       "      <th>P_3_median</th>\n",
       "      <th>P_3_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>S_22_count</th>\n",
       "      <th>S_23_count</th>\n",
       "      <th>S_25_count</th>\n",
       "      <th>P_3_count_binary</th>\n",
       "      <th>S_3_count_binary</th>\n",
       "      <th>S_7_count_binary</th>\n",
       "      <th>S_22_count_binary</th>\n",
       "      <th>S_23_count_binary</th>\n",
       "      <th>S_25_count_binary</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>12.140</td>\n",
       "      <td>0.09180</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>-0.438767</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.690</td>\n",
       "      <td>8.840</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>11.695</td>\n",
       "      <td>0.06790</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-0.854416</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.571</td>\n",
       "      <td>7.367</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>11.420</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>-0.109422</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.630</td>\n",
       "      <td>8.040</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>7.785</td>\n",
       "      <td>0.05615</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.953176</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>0.623</td>\n",
       "      <td>7.940</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>11.590</td>\n",
       "      <td>0.13530</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>-0.597527</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.560</td>\n",
       "      <td>6.855</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean  P_2_median  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...    0.9336      0.9385   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...    0.9000      0.9050   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...    0.8784      0.8850   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...    0.5990      0.5980   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...    0.8916      0.8794   \n",
       "\n",
       "   P_2_sum  P_2_data_range   P_2_iqr  P_2_correlation  P_3_mean  P_3_median  \\\n",
       "0   12.140         0.09180  0.012695        -0.438767    0.6800       0.690   \n",
       "1   11.695         0.06790  0.038086        -0.854416    0.5670       0.571   \n",
       "2   11.420         0.10645  0.027344        -0.109422    0.6180       0.630   \n",
       "3    7.785         0.05615  0.033203         0.953176    0.6110       0.623   \n",
       "4   11.590         0.13530  0.071289        -0.597527    0.5273       0.560   \n",
       "\n",
       "   P_3_sum  ...  S_22_count  S_23_count  S_25_count  P_3_count_binary  \\\n",
       "0    8.840  ...          13          13          13                 1   \n",
       "1    7.367  ...          13          13          13                 1   \n",
       "2    8.040  ...          13          13          13                 1   \n",
       "3    7.940  ...          13          13          13                 1   \n",
       "4    6.855  ...          13          13          13                 1   \n",
       "\n",
       "   S_3_count_binary  S_7_count_binary  S_22_count_binary  S_23_count_binary  \\\n",
       "0                 1                 1                  1                  1   \n",
       "1                 1                 1                  1                  1   \n",
       "2                 0                 0                  1                  1   \n",
       "3                 1                 1                  1                  1   \n",
       "4                 1                 1                  1                  1   \n",
       "\n",
       "   S_25_count_binary  target  \n",
       "0                  1       0  \n",
       "1                  1       0  \n",
       "2                  1       0  \n",
       "3                  1       0  \n",
       "4                  1       0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train = pd.read_csv('/home/ec2-user/SageMaker/Analytics_Data_Science/American_Express/Evan/amex_train_payment_spend.csv')\n",
    "\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b0fb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_ID', 'P_2_mean', 'P_2_median', 'P_2_sum', 'P_2_data_range',\n",
       "       'P_2_iqr', 'P_2_correlation', 'P_3_mean', 'P_3_median', 'P_3_sum',\n",
       "       'P_3_data_range', 'P_3_iqr', 'P_3_correlation', 'P_4_mean',\n",
       "       'P_4_median', 'P_4_sum', 'P_4_data_range', 'P_4_iqr', 'P_4_correlation',\n",
       "       'S_3_median', 'S_3_sum', 'S_3_data_range', 'S_3_iqr', 'S_3_correlation',\n",
       "       'S_5_data_range', 'S_5_iqr', 'S_5_correlation', 'S_6_mean',\n",
       "       'S_6_median', 'S_6_sum', 'S_6_mad', 'S_6_data_range', 'S_6_iqr',\n",
       "       'S_6_correlation', 'S_8_mean', 'S_8_median', 'S_8_sum',\n",
       "       'S_8_data_range', 'S_8_iqr', 'S_8_correlation', 'S_13_mean', 'S_13_sum',\n",
       "       'S_13_std', 'S_13_mad', 'S_13_data_range', 'S_13_iqr',\n",
       "       'S_13_correlation', 'S_25_mean', 'S_25_sum', 'S_25_std', 'S_25_mad',\n",
       "       'S_25_data_range', 'S_25_iqr', 'S_25_correlation', 'S_27_data_range',\n",
       "       'S_27_iqr', 'S_27_correlation', 'P_3_count', 'S_3_count', 'S_7_count',\n",
       "       'S_22_count', 'S_23_count', 'S_25_count', 'P_3_count_binary',\n",
       "       'S_3_count_binary', 'S_7_count_binary', 'S_22_count_binary',\n",
       "       'S_23_count_binary', 'S_25_count_binary', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618be3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training data-frame imputation complete -- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Imputing the train data-frame using the Mice Forest library\n",
    "\n",
    "## Defining the input variables and dropping categorical variables\n",
    "mf_train = new_train.drop(columns = ['customer_ID', 'target'])\n",
    "\n",
    "# Building the miceforest kernel\n",
    "kernel_train = mf.ImputationKernel(mf_train, datasets = 5, save_all_iterations = True)\n",
    "\n",
    "## Assigning the final imputed data-frames\n",
    "train_impute = kernel_train.complete_data(dataset = 0, inplace = False)\n",
    "\n",
    "## Adding \"customer_ID\" back into the data-frames\n",
    "train_impute = pd.concat([new_train[['customer_ID', 'target']], train_impute], axis = 1)\n",
    "\n",
    "## Sanity check\n",
    "print('-- Training data-frame imputation complete -- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds.sum()).head(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b406f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but RFECV was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but RFECV was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but RFECV was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Completed --\n"
     ]
    }
   ],
   "source": [
    "## Defining the input and target variables\n",
    "X = train_impute.drop(columns = ['customer_ID', 'target'])\n",
    "Y = train_impute['target']\n",
    "\n",
    "## Splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, stratify = Y)\n",
    "\n",
    "## Defining the customized scoring function \n",
    "amex_function = make_scorer(amex_metric, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "## Defining empty list to store results\n",
    "features_to_select = list()\n",
    "\n",
    "## Repeating steps 10 times:\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    ## Runing RFECV with Random Forest as a base algorithm\n",
    "    rf_rfecv = RFECV(estimator = RandomForestClassifier(n_estimators = 100, max_depth = 3), step = 1, scoring = amex_function, \n",
    "                     min_features_to_select = 5, cv = 3).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Appending results \n",
    "    features_to_select.append(rf_rfecv.support_)\n",
    "    \n",
    "## Putting results as data-frame\n",
    "features_to_select = pd.DataFrame(features_to_select, columns = X.columns)\n",
    "features_to_select = 100 * features_to_select.apply(np.sum, axis = 0) / features_to_select.shape[0]\n",
    "\n",
    "## Producing the final output data-frame\n",
    "output = pd.DataFrame(features_to_select).reset_index(drop = False)\n",
    "output.columns = ['Variable', 'Selected']\n",
    "output = output.sort_values(by = 'Selected', ascending = False).reset_index(drop = True)\n",
    "output.to_csv('feature_selection_results.csv', index = False)\n",
    "\n",
    "## Sanity check\n",
    "print('-- Completed --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ae3d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_2_mean</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S_3_median</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S_25_iqr</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S_25_data_range</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S_25_mad</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variable  Selected\n",
       "0         P_2_mean     100.0\n",
       "1       S_3_median     100.0\n",
       "2         S_25_iqr     100.0\n",
       "3  S_25_data_range     100.0\n",
       "4         S_25_mad     100.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features = pd.read_csv('/home/ec2-user/SageMaker/Analytics_Data_Science/American_Express/Evan/feature_selection_results.csv')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23153a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keeper = features[features['Selected'] == 100.0]\n",
    "\n",
    "keeper.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b029d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_2_mean , \n",
      "S_3_median , \n",
      "S_25_iqr , \n",
      "S_25_data_range , \n",
      "S_25_mad , \n",
      "S_25_std , \n",
      "S_25_sum , \n",
      "S_25_mean , \n",
      "S_13_sum , \n",
      "S_13_mean , \n",
      "S_8_sum , \n",
      "P_2_median , \n",
      "S_8_mean , \n",
      "S_5_correlation , \n",
      "S_3_sum , \n",
      "S_8_median , \n",
      "P_2_sum , \n",
      "P_2_data_range , \n",
      "P_3_mean , \n",
      "P_3_sum , \n",
      "P_2_correlation , \n",
      "P_4_mean , \n",
      "P_3_median , \n",
      "P_4_sum , \n"
     ]
    }
   ],
   "source": [
    "for var in keeper['Variable']:\n",
    "    print(var, ', ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
